description: Implementation plan (token-optimized mirror of .users/context/plan.md)

strategy: "Deploy first, add features incrementally. Every push = new ISO."

phases:
  phase_0:
    name: "Deploy pipeline"
    timeline: "Day 1-3"
    deliverable: "GitHub push → BlueBuild → ghcr.io image → ISO (GitHub Releases)"
    tasks:
      - "os/recipe.yml (BlueBuild recipe, base: bazzite)"
      - ".github/workflows/build.yml (GitHub Actions)"
      - "ISO generation (ublue-os/isogenerator)"
    done_when: "USB boot = Bazzite + Node.js (no custom yet)"

  phase_1:
    name: "Avatar on screen"
    timeline: "Week 1"
    deliverable: "Boot → Alpha VRM avatar auto-starts on screen"
    stack: "Tauri 2, React 18+/TypeScript/Vite, Three.js r0.182, @pixiv/three-vrm ^3.4.5, shadcn/ui, Zustand, Biome"
    tasks:
      step_1_init:
        name: "Tauri 2 + React project init"
        items:
          - "React + TS + Vite in shell/"
          - "Biome config (tab, double quote, semicolons)"
          - "shadcn/ui, Three.js, @pixiv/three-vrm, zustand install"
          - "Tauri 2 backend (Cargo.toml, tauri.conf.json, main.rs, lib.rs)"
      step_2_vrm_core:
        name: "AIRI VRM core extraction"
        copy_as_is:
          - { from: "stage-ui-three/composables/vrm/core.ts", to: "src/lib/vrm/core.ts" }
          - { from: "stage-ui-three/composables/vrm/loader.ts", to: "src/lib/vrm/loader.ts" }
          - { from: "stage-ui-three/composables/vrm/utils/eye-motions.ts", to: "src/lib/vrm/eye-motions.ts" }
          - { from: "stage-ui-three/assets/vrm/animations/idle_loop.vrma", to: "public/animations/idle_loop.vrma" }
        extract_pure_functions:
          - "loadVRMAnimation, clipFromVRMAnimation, reAnchorRootPositionTrack → src/lib/vrm/animation.ts"
      step_3_react_hooks:
        name: "Vue → React hooks porting"
        items:
          - "useBlink.ts — Vue ref() → useRef, blink timing logic"
          - "useIdleEyes.ts — Vue ref() → useRef, saccade logic"
      step_4_avatar_canvas:
        name: "AvatarCanvas component"
        items:
          - "Three.js WebGLRenderer + Scene + Camera setup"
          - "VRM loading via core.ts"
          - "idle animation playback"
          - "Render loop order: animation → humanoid → lookAt → blink → saccade → expression → springBone"
      step_5_tauri_window:
        name: "Tauri window config"
        items:
          - "Default window (transparent/borderless = Phase 2)"
          - "App icon, title: Cafelua Shell"
      step_6_integration:
        name: "Integration test"
        items:
          - "pnpm tauri dev → avatar visible with idle animation"
    done_when: "USB boot → Alpha avatar visible with idle animation + blink + saccade"
    reuse: "AIRI: Three.js + @pixiv/three-vrm (stage-ui-three)"

  phase_2:
    name: "Chat with Alpha"
    timeline: "Week 2"
    deliverable: "Text chat with Alpha, avatar lip-sync + emotions"
    llm_providers: "xAI (Grok), Google (Gemini), Anthropic (Claude) — see project-careti providers for reference"
    default_provider: "Google (Gemini) — primary for chat/TTS/vision; Claude for coding tasks"
    compatibility:
      aaif: "AAIF standard (Agentic AI Foundation, Linux Foundation 2025.12)"
      pillars:
        - "AGENTS.md (context layer, OpenAI donated)"
        - "SKILL.md (execution layer, procedural knowledge)"
        - "MCP (connectivity layer, Anthropic donated)"
      claude_code: "Full compatibility — CLAUDE.md, .claude/ ↔ .agents/ interoperable"
      careti_context: "Agent must consume project-careti .agents/ context as-is"
      reference: "project-careti F06 (careti-docs/features.en/f06-agent-standard-claude-compat.md)"
    cost_tracking: "Per-request cost display (project-careti provider pattern)"
    tasks:
      - "Agent core: LLM providers (xAI/Google/Claude), stdio protocol"
      - "AAIF context consumption (.agents/ + AGENTS.md hierarchy)"
      - "Tauri stdio bridge (spawn agent-core as child process)"
      - "Chat panel UI + streaming response + cost display"
      - "Avatar emotion mapping + lip-sync (Google TTS)"
      - "Onboarding: API key setup on first boot (support xAI, Google, Claude keys)"
    done_when: "USB boot → API key → chat with Alpha (lip-sync + emotions + cost visible)"
    reuse: "Careti: stdio-adapter.ts, lib.rs, LLM providers (xAI/Google/Claude), F06 context system"
    public_demo: true

  phase_3:
    name: "Alpha does work"
    timeline: "Week 3-4"
    deliverable: "Alpha can edit files, run terminal commands, search web"
    tasks:
      - "Tool system: file_read ✅, file_write ✅, apply_diff ✅, execute_command ✅, browser ✅, search ✅, web_search ✅"
      - "Permission tiers (0-3) + approval UI ✅"
      - "Audit log (SQLite) ✅"
      - "Work progress panel ✅"
      - "Sub-agents ✅ (sequential + parallel spawn via Gateway RPC)"
    status: "complete"
    done_when: "Alpha executes real OS tasks with permission system"
    reuse: "Careti: tools, SmartEditEngine, sub-agent pattern"

  phase_4:
    name: "Always-on daemon"
    timeline: "Week 5-7"
    deliverable: "Gateway daemon + external channels + memory"
    tasks:
      - "Gateway WebSocket server (systemd user service)"
      - "Discord bot + Telegram bot channels"
      - "Memory persistence (SQLite + vector search)"
      - "Skills system (weather, memo, system status)"
    done_when: "OS boot → auto-start → external channel access → remembers context"
    reuse: "MoltBot: Gateway pattern, channel SDKs, Skills"

  phase_5:
    name: "Gaming with Alpha"
    timeline: "Week 8+"
    deliverable: "Co-play Minecraft, game overlay avatar"
    tasks:
      - "Minecraft agent (Mineflayer, autonomous actions)"
      - "Generic game support (screen capture + vision model)"
      - "Game overlay avatar + voice chat"
    done_when: "Alpha joins Minecraft and plays autonomously"
    reuse: "AIRI: services/minecraft/, Mineflayer"

attention_points:
  phase_0: "Deploy pipeline = highest priority. Everything else layers on top."
  phase_2: "Public demo point. Must be polished enough to share."
  security: "Permission tiers active from Phase 3. Audit log from day one."
