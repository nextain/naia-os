description: Implementation plan (token-optimized mirror of .users/context/plan.md)

strategy: "Deploy first, add features incrementally. Every push = new ISO."

phases:
  phase_0:
    name: "Deploy pipeline"
    timeline: "Day 1-3"
    deliverable: "GitHub push → BlueBuild → ghcr.io image → ISO (GitHub Releases)"
    tasks:
      - "os/recipe.yml (BlueBuild recipe, base: bazzite)"
      - ".github/workflows/build.yml (GitHub Actions)"
      - "ISO generation (ublue-os/isogenerator)"
    done_when: "USB boot = Bazzite + Node.js (no custom yet)"

  phase_1:
    name: "Avatar on screen"
    timeline: "Week 1"
    deliverable: "Boot → Alpha VRM avatar auto-starts on screen"
    stack: "Tauri 2, React 18+/TypeScript/Vite, Three.js r0.182, @pixiv/three-vrm ^3.4.5, shadcn/ui, Zustand, Biome"
    tasks:
      step_1_init:
        name: "Tauri 2 + React project init"
        items:
          - "React + TS + Vite in shell/"
          - "Biome config (tab, double quote, semicolons)"
          - "shadcn/ui, Three.js, @pixiv/three-vrm, zustand install"
          - "Tauri 2 backend (Cargo.toml, tauri.conf.json, main.rs, lib.rs)"
      step_2_vrm_core:
        name: "AIRI VRM core extraction"
        copy_as_is:
          - { from: "stage-ui-three/composables/vrm/core.ts", to: "src/lib/vrm/core.ts" }
          - { from: "stage-ui-three/composables/vrm/loader.ts", to: "src/lib/vrm/loader.ts" }
          - { from: "stage-ui-three/composables/vrm/utils/eye-motions.ts", to: "src/lib/vrm/eye-motions.ts" }
          - { from: "stage-ui-three/assets/vrm/animations/idle_loop.vrma", to: "public/animations/idle_loop.vrma" }
        extract_pure_functions:
          - "loadVRMAnimation, clipFromVRMAnimation, reAnchorRootPositionTrack → src/lib/vrm/animation.ts"
      step_3_react_hooks:
        name: "Vue → React hooks porting"
        items:
          - "useBlink.ts — Vue ref() → useRef, blink timing logic"
          - "useIdleEyes.ts — Vue ref() → useRef, saccade logic"
      step_4_avatar_canvas:
        name: "AvatarCanvas component"
        items:
          - "Three.js WebGLRenderer + Scene + Camera setup"
          - "VRM loading via core.ts"
          - "idle animation playback"
          - "Render loop order: animation → humanoid → lookAt → blink → saccade → expression → springBone"
      step_5_tauri_window:
        name: "Tauri window config"
        items:
          - "Default window (transparent/borderless = Phase 2)"
          - "App icon, title: Cafelua Shell"
      step_6_integration:
        name: "Integration test"
        items:
          - "pnpm tauri dev → avatar visible with idle animation"
    done_when: "USB boot → Alpha avatar visible with idle animation + blink + saccade"
    reuse: "AIRI: Three.js + @pixiv/three-vrm (stage-ui-three)"

  phase_2:
    name: "Chat with Alpha"
    timeline: "Week 2"
    deliverable: "Text chat with Alpha, avatar lip-sync + emotions"
    llm_providers: "xAI (Grok), Google (Gemini), Anthropic (Claude) — see project-careti providers for reference"
    default_provider: "Google (Gemini) — primary for chat/TTS/vision; Claude for coding tasks"
    compatibility:
      aaif: "AAIF standard (Agentic AI Foundation, Linux Foundation 2025.12)"
      pillars:
        - "AGENTS.md (context layer, OpenAI donated)"
        - "SKILL.md (execution layer, procedural knowledge)"
        - "MCP (connectivity layer, Anthropic donated)"
      claude_code: "Full compatibility — CLAUDE.md, .claude/ ↔ .agents/ interoperable"
      careti_context: "Agent must consume project-careti .agents/ context as-is"
      reference: "project-careti F06 (careti-docs/features.en/f06-agent-standard-claude-compat.md)"
    cost_tracking: "Per-request cost display (project-careti provider pattern)"
    tasks:
      - "Agent core: LLM providers (xAI/Google/Claude), stdio protocol"
      - "AAIF context consumption (.agents/ + AGENTS.md hierarchy)"
      - "Tauri stdio bridge (spawn agent-core as child process)"
      - "Chat panel UI + streaming response + cost display"
      - "Avatar emotion mapping + lip-sync (Google TTS)"
      - "Onboarding: API key setup on first boot (support xAI, Google, Claude keys)"
    done_when: "USB boot → API key → chat with Alpha (lip-sync + emotions + cost visible)"
    reuse: "Careti: stdio-adapter.ts, lib.rs, LLM providers (xAI/Google/Claude), F06 context system"
    public_demo: true

  phase_3:
    name: "Alpha does work"
    timeline: "Week 3-4"
    deliverable: "Alpha can edit files, run terminal commands, search web"
    tasks:
      - "Tool system: file_read ✅, file_write ✅, apply_diff ✅, execute_command ✅, browser ✅, search ✅, web_search ✅"
      - "Permission tiers (0-3) + approval UI ✅"
      - "Audit log (SQLite) ✅"
      - "Work progress panel ✅"
      - "Sub-agents ✅ (sequential + parallel spawn via Gateway RPC)"
    status: "complete"
    done_when: "Alpha executes real OS tasks with permission system"
    reuse: "Careti: tools, SmartEditEngine, sub-agent pattern"

  phase_4:
    name: "Always-on daemon"
    timeline: "Week 5-7"
    deliverable: "Gateway daemon + external channels + memory"
    status: "in_progress"
    strategy: "Gateway first → Phase 3 runtime verification → then new features"
    tasks:
      step_4_0:
        name: "OpenClaw Gateway local setup"
        description: "Get Gateway running locally to unlock Phase 3 runtime verification"
        status: "complete"
        items:
          - "OpenClaw install + config (setup-openclaw.sh already exists) ✅"
          - "Gateway local start (cafelua-gateway-wrapper) ✅"
          - "Shell → Agent → Gateway WebSocket connection verified ✅"
          - "Gateway auto-lifecycle in Tauri (spawn/health/shutdown) ✅"
        done_when: "gateway_health() returns true, Agent connects via WebSocket"
      step_4_0_lifecycle:
        name: "Gateway auto-lifecycle"
        description: "Tauri app manages Gateway process automatically"
        status: "complete"
        items:
          - "GatewayProcess struct + AppState integration ✅"
          - "Hybrid strategy: reuse if running, spawn if not ✅"
          - "Node.js 22+ detection with nvm fallback ✅"
          - "Health check polling (5s timeout, 500ms interval) ✅"
          - "Graceful shutdown: only kill self-spawned Gateway ✅"
          - "gateway_status event emit to frontend ✅"
      step_4_1:
        name: "Phase 3 E2E verification"
        description: "Verify all Phase 3 tools work through live Gateway"
        status: "complete"
        items:
          - "8 tools runtime test (read/write/diff/command/search/web_search/browser/spawn) ✅"
          - "Permission approval flow (Tier 1-2 modal actual UI) ✅"
          - "Sub-agent parallel execution real verification ✅"
          - "Audit log actual recording check ✅"
          - "Fix bugs discovered during runtime testing ✅"
        done_when: "All 8 tools execute successfully through Gateway"
      step_4_2:
        name: "User testing (manual)"
        description: "Manual end-to-end testing via pnpm tauri dev"
        items:
          - "Chat → tool invocation → result display"
          - "File read/write/edit scenarios"
          - "Command execution scenarios"
          - "Error cases (permission reject, timeout)"
        done_when: "User confirms Phase 3 tools work correctly"
      step_4_3:
        name: "Skills system"
        status: "complete"
        items:
          - "Skill registry + matching ✅"
          - "Built-in skills (time ✅, memo ✅, system_status ✅) via Gateway"
          - "Custom skill loader (~/.cafelua/skills/) ✅"
          - "E2E tests: 04-skill-time, 05-skill-system, 06-skill-memo ✅"
        known_issues:
          - "skill_memo 'list all' hangs occasionally (Gateway response timeout)"
      step_4_3b:
        name: "OpenClaw skills migration (all 51)"
        status: "planned"
        description: "Port ALL 51 OpenClaw built-in skills to Cafelua Shell. Can run parallel with 4.4."
        current: "4 built-in (time, memo, system_status, weather)"
        target: "All 51 OpenClaw built-in skills + E2E tests for each"
        strategy: |
          Primary: Gateway proxy via ~/.cafelua/skills/ manifest (bulk migration).
          Each skill gets a skill.json manifest → Gateway proxies to OpenClaw skill.
          Batch approach: generate manifests programmatically from OpenClaw SKILL.md frontmatter.
          E2E test per skill: invoke via agent → verify response format.
        skills_list:
          knowledge: "1password, apple-notes, bear-notes, notion, obsidian, nano-pdf, trello"
          tasks: "apple-reminders, things-mac, oracle"
          communication: "slack, discord, bluebubbles, imsg, himalaya, wacli"
          media: "video-frames, openai-image-gen, nano-banana-pro, gifgrep, songsee, summarize"
          audio: "openai-whisper, openai-whisper-api, sherpa-onnx-tts, sag, voice-call"
          music: "sonoscli, blucli, spotify-player"
          smart_home: "openhue, eightctl, camsnap"
          dev: "coding-agent, github, mcporter, skill-creator"
          productivity: "gog, goplaces, blogwatcher, food-order, ordercli"
          ai: "gemini, model-usage, clawhub"
          system: "tmux, healthcheck, session-logs, weather, canvas"
        testing: "E2E test per skill: shell/e2e-tauri/specs/09-skills-*.spec.ts"
        done_when: "All 51 skills registered + E2E tests passing."
      step_4_4:
        name: "Memory + UX + Onboarding"
        status: "complete"
        architecture: |
          2-tier memory: Short-Term Memory (STM) + Long-Term Memory (LTM).
          STM = current session full messages (zustand + SQLite).
          LTM = session summaries + semantic facts (SQLite, filled by LLM later).
          Search: SQLite LIKE (4.4a) → FTS5 BM25 (4.4b) → embeddings (4.5) → sLLM (5+).
          MemoryProcessor interface: pluggable summarize/embed/search.
        execution_order: "4.4a ✅ → 4.4-ui ✅ → 4.4-onboard ✅ → 4.4b ✅ → 4.4c ✅"
        order_rationale: |
          4.4-ui first: tab architecture is structural foundation for history/settings/onboarding.
          4.4-onboard second: built on new tab UI, creates user profile (name) used by context recall.
          4.4b third: uses profile from onboarding + session summaries.
          4.4c last: extends 4.4b with fact extraction.
        sub_phases:
          step_4_4a:
            name: "Conversation persistence (STM)"
            status: "complete"
            items:
              - "Rust memory.rs: sessions + messages tables (SQLite, rusqlite) ✅"
              - "sessions.summary column prepared (empty, filled in 4.4b) ✅"
              - "Tauri commands: 8 memory commands registered ✅"
              - "Frontend db.ts: invoke() wrappers + ChatMessage↔MessageRow conversion ✅"
              - "Chat store: sessionId, setMessages, newConversation ✅"
              - "ChatPanel: load previous session on mount, new conversation (+) button ✅"
              - "ChatPanel: ESC key / ■ button to cancel streaming ✅"
              - "Avatar emotion reset to neutral on streaming finish ✅"
              - "E2E test: 08-memory.spec.ts (4 tests: persist, refresh, new chat, fresh session) ✅"
              - "i18n: chat.newConversation ✅"
            tests: "Rust 53, Vitest 143, E2E 8 specs (15 tests) — all passing"
          step_4_4_ui:
            name: "Shell UX enhancements"
            status: "complete"
            description: "Cost dashboard, session history tab, error filter, message queue"
            items:
              - "CostDashboard.tsx: provider/model별 비용 그룹핑 테이블 (드롭다운)"
              - "HistoryTab.tsx: 4번째 탭, getRecentSessions(50), 클릭→로드, 삭제"
              - "WorkProgressPanel: 에러 카운트 클릭→필터 on/off"
              - "Chat store: messageQueue, enqueueMessage, streaming 중 입력 가능"
              - "Rust memory.rs: get_sessions_with_count() (메시지 수 서브쿼리)"
              - "i18n: cost.*, history.*, progress.filter*, chat.queued"
            tests:
              - "CostDashboard.test.tsx: 그룹핑, 합계, 빈 상태"
              - "HistoryTab.test.tsx: 빈 상태, 목록, 클릭 로드, 삭제"
              - "chat.test.ts: 큐 동작"
              - "E2E 09-history.spec.ts: 히스토리 탭 동작"
            done_when: "Settings/history/cost accessible as tabs, error filter works, message queue works."
          step_4_4_onboard:
            name: "Onboarding wizard (first-run experience)"
            status: "complete"
            description: "7-step conversational wizard: agentName → userName → character → personality → provider → apiKey → complete"
            depends_on: "4.4-ui (built on tab architecture)"
            items:
              - "OnboardingWizard.tsx: 5단계 풀스크린 오버레이"
              - "config.ts: userName field, isOnboardingComplete()"
              - "App.tsx: 온보딩 미완료 시 위자드 렌더링"
              - "persona.ts: buildSystemPrompt(persona, context) 시그니처 변경, userName 주입"
              - "lib.rs: validate_api_key Tauri command (프로바이더별 REST 호출)"
              - "i18n: onboard.* 키"
            tests:
              - "OnboardingWizard.test.tsx: 단계 진행, 이름, API 키 검증, 완료 콜백"
              - "E2E 02-configure 업데이트 or 10-onboarding.spec.ts"
            done_when: "First boot → wizard → name + API key → Alpha greets by name."
          step_4_4b:
            name: "Session summarization + context recall"
            status: "complete"
            depends_on: "4.4-onboard (user profile provides name/context)"
            items:
              - "memory-processor.ts: summarizeSession() — LLM REST 호출로 2-3줄 요약"
              - "memory.rs: FTS5 가상 테이블 + 트리거, update_session_summary(), search_fts()"
              - "persona.ts: MemoryContext interface, 시스템 프롬프트에 요약/userName 주입"
              - "ChatPanel: handleNewConversation에 요약 호출, handleSend에 컨텍스트 로드"
              - "db.ts: updateSessionSummary(), searchMessagesFts()"
              - "i18n: chat.summarizing, chat.summarized"
            tests:
              - "memory-processor.test.ts: 요약 호출, 에러 처리 (fetch mock)"
              - "persona.test.ts: 컨텍스트 주입 테스트"
              - "Rust memory.rs: FTS5 테이블 생성, 검색, summary 업데이트"
            done_when: "New conversation gets context from previous sessions + knows user name."
          step_4_4c:
            name: "Semantic memory (facts)"
            status: "complete"
            depends_on: "4.4b (builds on summarization pipeline)"
            items:
              - "memory.rs: facts 테이블 (id, key, value, source_session, timestamps)"
              - "memory.rs: get_all_facts, upsert_fact, delete_fact"
              - "lib.rs: facts CRUD Tauri commands"
              - "db.ts: getAllFacts, upsertFact, deleteFact"
              - "memory-processor.ts: extractFacts() — LLM에 사실 추출 요청"
              - "SettingsTab: '기억 (Facts)' 섹션 (key-value 목록 + 삭제)"
              - "persona.ts: facts를 MemoryContext에 포함, 시스템 프롬프트에 주입"
              - "i18n: settings.memorySection, settings.factsEmpty, settings.factDelete, chat.extractingFacts"
            tests:
              - "memory-processor.test.ts: extractFacts, JSON 파싱, 에러 처리"
              - "Rust memory.rs: facts CRUD 테스트"
              - "SettingsTab.test.tsx: facts 목록 표시, 삭제"
            done_when: "Alpha remembers user preferences across sessions."
        future_phases:
          phase_4_5: "Gemini Embedding API for semantic search"
          phase_5_plus: "sLLM (Ollama/llama.cpp) for local summarize/embed"
      step_4_5:
        name: "External channels"
        items:
          - "Discord bot (discord.js)"
          - "Telegram bot (grammY)"
          - "External channels limited to Tier 0-1"
      step_4_6:
        name: "systemd auto-start integration"
        items:
          - "Gateway auto-start on boot"
          - "Health monitoring"
    done_when: "OS boot → auto-start → external channel access → remembers context"
    reuse: "MoltBot: Gateway pattern, channel SDKs, Skills"

  phase_5:
    name: "Gaming with Alpha"
    timeline: "Week 8+"
    deliverable: "Co-play Minecraft, game overlay avatar"
    tasks:
      - "Minecraft agent (Mineflayer, autonomous actions)"
      - "Generic game support (screen capture + vision model)"
      - "Game overlay avatar + voice chat"
    done_when: "Alpha joins Minecraft and plays autonomously"
    reuse: "AIRI: services/minecraft/, Mineflayer"

attention_points:
  phase_0: "Deploy pipeline = highest priority. Everything else layers on top."
  phase_2: "Public demo point. Must be polished enough to share."
  security: "Permission tiers active from Phase 3. Audit log from day one."
